Tasks to do

??         not analyzed
0  orig    nothing to do from origin
0 analyze  nothing urgent to do after analyze (maybe later)
0 irrelev  nothing to do, disagree with reviewer
1 analyze  nothing to do, like 0 analyze but with more priority
*  FT      done by Frederic Tuong
*  JF      done by JF
*  XM      done by Xiaomu
!  FT      TODO by Frederic Tuong
!  JF      TODO by JF
!  XM      TODO by Xiaomu
!  Vania   TODO, waiting for input by Vania


0  orig  | ----------------------- REVIEW 1 ---------------------
0  orig  | PAPER: 35
0  orig  | TITLE: First Steps Towards the Certification of an ARM Simulator
0  orig  | AUTHORS: Xiaomu Shi, Jean-Francois Monin, Frédéric Tuong and Frédéric Blanqui
0  orig  | 
0  orig  | OVERALL RATING: -1 (weak reject)
0  orig  | REVIEWER'S CONFIDENCE: 3 (high)
0  orig  | 
0  orig  | The paper reports on an experiment in Coq: a simulation proof between
0  orig  | a program in Coq that models an assembly instruction and a C program
0  orig  | that simulates it. The assembly instruction is ADC (add with carry)
0  orig  | from the ARM instruction set and the C program is part of simlight: a
0  orig  | simulator for the core ARM instruction set.  The semantics of C is
0  orig  | given by Compcert. Pseudo-code and C programs are extracted from the
0  orig  | ARM reference manual (semi-?)automatically but this is referred to as
0  orig  | previous work [5]. This experiment is presented as the first step
0  orig  | towards a formally verified simulator.
0  orig  | 
0 analyze| The approach is well-motivated (sec.1). (But coupled with sec.2, this
0 analyze| makes for a long introduction.)
0  orig  |
1 analyze| I am not sure that enough has been done to make clear points about the
1 analyze| work. The size of the experiment is moderate (what's new in this paper seems
1 analyze| to be around a few thousands lines), what makes it difficult
1 analyze| to draw general conclusions. Compared with lemmas 1&2, lemmas/axioms 3 see
1 analyze| difficult. The fact that they are axiomatized is likely to hide unanticipated
1 analyze| difficulties.  Indeed, whereas lemmas 1&2 are about expressions, 3&4
1 analyze| are about programs. "The 10 remaining ... should require a similar
1 analyze| effort" (p.14): I really don't see what allows you to say that. "If we
1 analyze| prove ... of ADC ... we can expect to automate ..." (p.12): isn't this
1 analyze| far-fetched given the fact that there are still axioms lurking around?
0  orig  |
*  JF&XM | I think that the writing of the paper makes it difficult to read for
*  JF&XM | the reader unaware of, at least, the technicalities of related work
*  JF&XM | (hasty writing?). Important explanations are lacking (for example:
*  JF&XM | "projection" p.5, "projective relation" p.14, "projective-related"
*  JF&XM | fig.2 are not explained but used in the statement of the main result
*  JF&XM | thm.1 and the explanations of lem.2).  Code is displayed that is
*  FT    | barely explained (for example: ADC functions (ADC_pseudocode,
*  FT    | ADC_Coq, ADC_simlight, ADC_Coq_simlight); what's the difference between
*  JF    | set_reg and set_reg_or_pc?; etc, etc). Several notations are not
*  JF    | explained (for example: "S" that appears in all the pieces of code and
*  JF    | lemmas 1&2). Several of the rare explanations take the form of
*  JF    | implicit forward references (for example: CPSR appears a lot in sec.3
*  JF    | but it is explained p.10, SLv6_Processor appears in sec.4 but is
*  JF&XM | explained in p.12, copy_StatusRegister from 4.1 explained in
*  JF&XM | 4.2). Important things are assumed to be known about Compcert (for
*  JF&XM | example: claims are done that depend on the C memory model ("much more
*  JF&XM | complex" p.5, "their semantics operates on difference memory models
*  JF&XM | ... is not trivial" p.9 "the evil ... memory models" p.12) but their
*  JF&XM | is no concrete explanation; Internal, operation, etc. on p.11 seem to
*  JF&XM | be Compcert parlance).
0  orig  |
0 analyze| I wonder whether related work have been explored thoroughly. What
0 analyze| about seL4?  They do simulation proofs between C and a functional
0 analyze| language and go at length explaining proof techniques in, say, TPHOLs
0 analyze| 2009.
0  orig  |
0 analyze| Minor comments:
*  FT    | - typos: "occurs." l.2,p.10, "af" l.2,p.13
*  FT    | - both "Compcert" and "Compcert-C" are used
*  JF    | - fonts: ADC is sometimes in \tt, sometimes in \rm, ADC_Coq 
*  JF    | in thm1. is not in \tt, etc.
*  FT    | - p.11: l.3, what's a "mode"?
*  FT    | - p.11: "In summary, the translation of StatusRegister looks as follows:"
*  FT    | but what follows is the code for Transf_stm
*  JF    | - p.12: $ofs$ makes for ugly spacing
*  JF&XM | - thm1: exec_stmt seems to be a function in thm.1 but you just explained in sec.4.1 
*  JF&XM | that the semantics if given by a relation, it is confusing
0  orig  |
0  orig  |
0  orig  | ----------------------- REVIEW 2 ---------------------
0  orig  | PAPER: 35
0  orig  | TITLE: First Steps Towards the Certification of an ARM Simulator
0  orig  | AUTHORS: Xiaomu Shi, Jean-Francois Monin, Frédéric Tuong and Frédéric Blanqui
0  orig  |
0  orig  | OVERALL RATING: 2 (accept)
0  orig  | REVIEWER'S CONFIDENCE: 3 (high)
0  orig  |
0  orig  | >>> SUMMARY
0  orig  |
0  orig  | The authors outline a design for a verified SoC simulator. As a first step,
0  orig  | they focus on verifying the simulation of the processor component. Their
0  orig  | system automatically extracts a formal model (in Coq) of the processor's
0  orig  | ISA from its reference manual. They also automatically extract code (in C)
0  orig  | to simulate each instruction. To verify the simulation code, they prove
0  orig  | that its behavior matches the behavior of the formal model.
0  orig  |
0  orig  | The authors have partially completed an instance of their system targeting
0  orig  | ARM: extraction of the formal model and the simulation code is complete
0  orig  | (modulo pretty printing C ASTs expressed in Coq to concrete C syntax) as is
0  orig  | verification for the code simulating the ADC instruction (modulo axioms
0  orig  | about supporting C functions that encode common ARM operations).
0  orig  |
0  orig  | >>> DETAILS
0  orig  |
0  orig  | The authors manually developed two analogous libraries to support simulating
0  orig  | ARM instructions, one in Coq and another in C. These libraries provide
0  orig  | services like operating on bit ranges and communicating with co-processors.
0  orig  |
0  orig  | For each ARM instruction I in the manual, two functions are automatically
0  orig  | generated: SimI_coq (in the Calculus of Constructions (CoC)) and SimI_c (in
0  orig  | C). These functions may call helper functions defined in the ARM simulation
0  orig  | library for their language.
0  orig  |
0  orig  | The goal of verification is proving SimI_coq and SimI_c equivalent.
0  orig  | Specifically, the correctness theorem is roughly of the form:
0  orig  |
0  orig  |   IF
0  orig  |     A and A' are "equivalent" inputs
0  orig  |     SimI_coq(A) = B
0  orig  |     SimI_c(A') = B'
0  orig  |   THEN
0  orig  |     B and B' are "equivalent" outputs
0  orig  |
0  orig  | Where "equivalence" of inputs and outputs handles the differences of value
0  orig  | representation between Coq and C.
0  orig  |
0  orig  | In order to reason about the equivalence of CoC and C functions, the
0  orig  | authors actually extract the C simulation code directly to CompCert C ASTs,
0  orig  | that is, they represent the C simulation code as a data structure in Coq.
0  orig  | To reason about the behavior of C programs they use the C semantics
0  orig  | provided by CompCert. To eventually compile and run the C code, they pretty
0  orig  | print it to concrete C syntax and use traditional tools.
0  orig  |
0  orig  | For now, the authors axiomatize the behavior of the ARM simulation library
0  orig  | written in C. This is not fundamental; they could eventually prove the Coq
0  orig  | and C libraries equivalent using the same techniques they employ for ARM
0  orig  | instructions.
0  orig  |
0  orig  | >>> STRENGTHS
0  orig  |
0  orig  | The automatic extraction of a formal spec from the manual is very
0  orig  | interesting. Since the spec for each instruction is extracted in the same
0  orig  | way, accidental omissions or mis-encodings (the sort of errors that plague
0  orig  | manual specifications) seem less likely. This is particularly important
0  orig  | because spec bugs remain a weak link in the chain of formal verification.
0  orig  |
0  orig  | The fact that the SimSoc team has adopted the authors' extraction
0  orig  | technique is a testament to the practicality of this approach.
0  orig  |
0  orig  | The authors provide a plan for formally verifying a large, complex C
0  orig  | program. Although verifying the first instruction took two weeks, the
0  orig  | difficulty should decrease as more instructions are verified. The automated
0  orig  | extraction of the spec likely saved many hours of tedious work.
0  orig  |
0  orig  | This project can serve as a template for verifying C programs in this
0  orig  | style. There is nothing specific to SoC in their verification technique.
0  orig  |
0  orig  | >>> WEAKNESSES
0  orig  |
0 analyze| The main weakness is motivation. This project serves as a great test bed
0 analyze| for the automated spec extraction and C program verification techniques,
!  Vania | but it's not clear why it's important to verify SoC simulators.
0  orig  |
!  Vania | Verification should reduce overall costs. Usually that restricts
!  Vania | verification to components of the end system (e.g. control software) or
!  Vania | tools that must preserve the correctness of those components (e.g.
!  Vania | compilers). In contrast, the SoC simulator is only used for prototyping
!  Vania | before hardware is available and for debugging. Since the simulator itself
!  Vania | is not part of any end system, it is not clear why it ought to be verified.
0  orig  |
*  Vania | To address this criticism, the authors could provide examples where
*  Vania | simulator bugs were so expensive that it would have been cheaper to verify
*  Vania | the simulator than simply test it.
0  orig  |
*  Vania | At one point the paper mentions that previous versions of the ARM simulator
*  Vania | still contained bugs even after extensive testing. The authors should
*  Vania | mention what sort of bugs those were and how their verification is guaranteed
*  Vania | to eliminate that type of error. 
0  orig  |
0  orig  | The paper also leaves some important questions unanswered:
0  orig  |
*  JF    |   In the ultimate design, what is assumed correct and what is proven?
*  JF    |   (i.e. What is the Trusted Computing Base (TCB)?)
0  orig  |
0 analyze|   The paper outlines how to verify instruction simulators, but does not
0 analyze|   explain how to compose these into a chip simulator, nor on how to
0 analyze|   compose a chip simulator with other components to achieve a fully
0 analyze|   verified, complete SoC simulator. The authors should briefly outline how these
0 analyze|   verifications will be done in the future. If it is too difficult to
0 analyze|   predict, the authors should at least outline a promising approach to
0 analyze|   suggest that the goal is feasible.
0  orig  |
1 analyze|   Since the authors are willing to trust the Coq model of ARM extracted
1 analyze|   from the manual, why not just extract the Coq model to OCaml and run it
1 analyze|   directly? Presumably, performance would be unacceptably bad. That claim
1 analyze|   should be backed up with performance numbers.

Claude:
I don't remember the exact figures, but it was about a few kips for the
OCaml simulator, compared to a few Mips for simlight (and around 100 Mips
for a simulator with dynamic translation).
However, it was a little more complicated, because the Ocaml simulator was
slowing done during the simualtion. Indeed, the duration of a memory read
was proportional to the number of previous memory writes. So after a few
minutes of execution, the Ocaml simulator was simulating below 100 ips.

0  orig  |
*  JF    | The paper is slightly difficult to follow and would benefit by reorganizing
*  JF    | to a more "top-down" style.
0  orig  |
0  orig  | >>> QUESTIONS
0  orig  |
*  XM    | How are basic datatypes represented in the Coq spec?  Are machine integers
*  XM    | represented with CompCert's formalization of 32 bit integers?  If not, how
*  XM    | are low level details like overflow handled?
0  orig  |
!  XM    | How are interrupts represented and handled in both the Coq and C
!  XM    | simulators?
0  orig  |
0 irrelev| Would it be difficult to provide this stronger guarantee?
0  orig  |
0 irrelev|   IF
0 irrelev|     A and A' are "equivalent" inputs
0 irrelev|     SimI_coq(A) = B
0 irrelev|   THEN
0 irrelev|     SimI_c(A') = B'
0 irrelev|     B and B' are "equivalent" outputs
0  orig  |
*  JF    | Why is each C function for simulating an instruction extracted as its own
*  JF    | program? Why not extract a single library program with one function per
*  JF    | ARM instruction?
0  orig  |
0 analyze| What causes the 50% - 70% slowdown of CompCert compared to GCC?  In our
0 analyze| experience, CompCert compares favorably to GCC -O1.
0  orig  |
0  orig  | >>> NIT PICKS
0  orig  |
*  FT    | In the Coq function for ADC, you may want to mention that the monad
*  FT    | implicitly propagates errors. Readers who are unfamiliar with monads may
*  FT    | otherwise be confused as to where all the "undefined" states went.
0  orig  |
*  Vania | Page 1: Why are native simulators the "most abstract"?
0  orig  |
*  Vania | Page 2: What do you mean by "realistic speed" for simulation?
0  orig  |
*  JF    | Page 2: "kind of functional simulators can" =>
*  JF    |         "kind of functional simulator can" =>
0  orig  |
*  JF    | Page 3: "We choosed" => "We chose"
0  orig  |
*  JF    | Page 10: "brute impression" => "naive approach"
0  orig  |
*  JF    | Page 4:
*  JF    |   You suggest that staying within an "extensively tested" subset of C
*  JF    |   means that using GCC is safe. Recent results from  Regehr et al. 
*  JF    |   suggest otherwise. For example, GCC micompiled "(x / -1) *= 1" to
*  JF    |   "0". Perhaps your claim is true with optimizations turned off.
*  JF    |   However, with no optimizations, GCC may actually be slower than
*  JF    |   CompCert!

Claude:
I don't understand the reviewer example. For me, it's not C. And gcc agrees
with me ("invalid lvalue in assignment").

0  orig  |
0  orig  |
0  orig  | ----------------------- REVIEW 3 ---------------------
0  orig  | PAPER: 35
0  orig  | TITLE: First Steps Towards the Certification of an ARM Simulator
0  orig  | AUTHORS: Xiaomu Shi, Jean-Francois Monin, Frédéric Tuong and Frédéric Blanqui
0  orig  |
0  orig  | OVERALL RATING: 0 (borderline paper)
0  orig  | REVIEWER'S CONFIDENCE: 3 (high)
0  orig  |
0  orig  | The paper presents the formal certification in Coq of SimLight, a
0  orig  | lightweight subset of the SimSoc simulator for ARM.  The proof of
0  orig  | correctness of the simulator is achieved as follows.  We derive a Copw
0  orig  | specification of the ARM instruction set, as well as a model of the
0  orig  | simulator in Coq (in CompCert C).  The proof of correspondence
0  orig  | connects the two.
0  orig  |
0  orig  | This is clearly important research area.  Certification of simulators
0  orig  | is an important piece in both hardware and software verification
0  orig  | areas.  Accuracy of simulators is of paramount importance for hardware
0  orig  | verification, since it is used as a golden model.  It is important
0  orig  | also for software in the SoC domain, since software is often developed
0  orig  | and tested based on the functional characteristics of the simulator
0  orig  | before the hardware is available.
0  orig  |
0 analyze| Nevertheless, my evaluation of the paper has a low score, since I
0 analyze| don't see a specific contribution here, either in insight or in
0 analyze| complexity of systems handled, that pushes the state of the art.
0  orig  |
0 analyze| On the complexity side, the work is pretty early at this point.  After
0 analyze| all, while ADC is a good illustrative example, its verification is not
0 analyze| surprising.  I do encourage the authors to continue this work and
0 analyze| verify more intensive instructions, of course.  But at this stage I am
0 analyze| not sure that they have a non-trivial subset of the ARM instruction
0 analyze| set to justify publication.
0  orig  |
0 analyze| On the insight front, I did not read anything in the paper that
0 analyze| surprised me, or did not seem well-known.  The idea of the
0 analyze| verification, the way the authors are proceeding, reminds me of Hunt's
0 analyze| early work in 1985 with microprocessor verification.  See for example:
0  orig  |
*  JF    | @Book{fm8501,
*  JF    |   author     = "Hunt, Jr., W. A.",
*  JF    |   title      = "{FM8501: A Verified Microprocessor}",
*  JF    |   publisher  = "Springer-Verlag",
*  JF    |   series     = "LNAI",
*  JF    |   volume     = "795",
*  JF    |   year       = 1994
*  JF    | }  
0  orig  |
!  JF    | More generally, the Boyer-Moore theorem proving community (Nqthm and
!  JF    | ACL2) has done a significant amount of work over the last two decades
!  JF    | towards formalization and certification of the simulators, for
!  JF    | machines ranging from Rockwell Collins AAMP to the Java Virtual
!  JF    | machine, and it is surprising to not even see a mention of any of this
!  JF    | in the paper.  The techniques suggested by the authors seem very close
!  JF    | to those developed by that community, and I expected a careful
!  JF    | comparison of this work with theirs.
0  orig  |
*  JF    | choosed => choose
*  JF    | sacrifying => sacrificing
0  orig  |
0  orig  |
0  orig  | ----------------------- REVIEW 4 ---------------------
0  orig  | PAPER: 35
0  orig  | TITLE: First Steps Towards the Certification of an ARM Simulator
0  orig  | AUTHORS: Xiaomu Shi, Jean-Francois Monin, Frédéric Tuong and Frédéric Blanqui
0  orig  |
0  orig  | OVERALL RATING: 2 (accept)
0  orig  | REVIEWER'S CONFIDENCE: 3 (high)
0  orig  |
0  orig  | The authors describe the development and (still in progress)
0  orig  | verification of a simulator for the ARM architecture. The method they
0  orig  | use is based on autogeneration from the actual architecture manual,
0  orig  | which is an unusual and commendable approach to the known difficulty
0  orig  | of validating such a specification. On the whole, this is an unusual
0  orig  | and original piece of work that I recommend for publication.
0  orig  |
0  orig  | Although the headline accomplishments as far as verification goes do
0  orig  | not look impressive at first sight, I agree with the authors'
0  orig  | assessment that once a single instruction like ADC is verified
0  orig  | successfully, most others should be routine modifications, and one
0  orig  | hopes that this regularity could be exploited by the computer in a
0  orig  | generic proof method, not by human beings. The main question that
1 analyze| remains would then be the difficulty of the instruction decoding part.
1 analyze| Some estimates of how long this part might take would certainly be of
1 analyze| interest, if the authors have any concrete idea.
0  orig  |
1 analyze| A different approach one might take is to automatically extract OCaml
1 analyze| code from the Coq specification and use that. Has such an approach
1 analyze| been tried? I would imagine it is much slower, but correctness would
1 analyze| almost follow a priori. Some concrete experiments would be
1 analyze| instructive.
0  orig  |
0 analyze| An additional complementary idea might be to make a formal connection
0 analyze| with the specification mentioned in [8]. As the authors note, the aims
0 analyze| here are a little different, but it would be a valuable extra "sanity
0 analyze| check" for both specs. After all the spec in [8] was derived in a more
0 analyze| manual way but has been under development for many years and connected
0 analyze| to actual hardware, which is a significant factor.
0  orig  |
!  JF&XM | I would prefer the authors to talk at more length about the question
!  JF&XM | of undefined or underspecified behaviour. In section 3.1 this is
!  JF&XM | mentioned briefly. It wasn't clear to me to what extent the ARM spec
!  JF&XM | allows nondeterministic behaviour, and to what extent various
!  JF&XM | implementations actually use the freedom to do things differently.
!  JF&XM | If this is widespread, then this makes the question of correctness
!  JF&XM | more subtle, and there is much more to it than simply failing in such
!  JF&XM | cases. I know x86 better than ARM, and for x86 I am sure that many
!  JF&XM | real programs rely on supposedly unspecified behaviour. Is the ARM
!  JF&XM | situation better in this respect?
